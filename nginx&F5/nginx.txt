nginx
	nginx:高性能的HTTP和反向代理服务器,同时支持作为IMAP/POP3/SMTP代理服务器.目前被很多网站应用为其HTTP软负载均衡器.高效的性能,良好的稳定性,丰富的功能集,实力配置文件和低系统资源的消耗正在被大型互联网公司青睐,使用nginx运行HTTP网站的数据分流.
	
	功能特点:
		1.工作在网络得到7层之上,可以针对HTTP应用做一些风流的策略,比如针对域名,目录结构;
		2.nginx对网络的依赖比较小.
		3.nginx安装和配置比较简单,测试起来比较方便.
		4.可以承担高的负载压力且稳定,一般能支撑超过1万次的并发.
		5.nginx可以通过端口检测到服务器内部的故障,比如根据服务器处理网页返回的状态码,超时等等,并且会把返回错误的请求重新提交到另一个节点,不过其中缺点就是不支持url来检测.
		6.nginx对请求的异步处理可以帮助节点服务器减轻负载.
		7.nginx能支持HTTP和email.
	F5的负载均衡功能
		其实看到Nginx的原理和功能，是不是觉得已经不需要F5了？当然也不是，F5毕竟是负载均衡的老前辈，一直以来都以功能强大，性能稳定著称，很多功能其实是软负载无法做到的。
		F5 BIG-IP用作HTTP负载均衡器的主要功能：
		1、F5 BIG-IP提供12种灵活的算法将所有流量均衡的分配到各个服务器，而面对用户，只是一台虚拟服务器。
		2、F5 BIG-IP可以确认应用程序能否对请求返回对应的数据。假如F5 BIG-IP后面的某一台服务器发生服务停止、死机等故障，F5会检查出来并将该服务器标识为宕机，从而不将用户的访问请求传送到该台发生故障的服务器上。这样，只要其它的服务器正常，用户的访问就不会受到影响。宕机一旦修复，F5 BIG-IP就会自动查证应用保证对客户的请求作出正确响应并恢复向该服务器传送。
		3、F5 BIG-IP具有动态Session的会话保持功能，笔者也是在网站中使用的F5将用户IP与Session通过F5进行的绑定，使其Session保持一致。
		4、F5 BIG-IP的iRules功能可以做HTTP内容过滤，根据不同的域名、URL，将访问请求传送到不同的服务器。
		

	静态资源服务器,反向代理,负载均衡等
	
	下载地址:http://nginx.org/en/download.html 
	
使用篇:
	静态资源服务器配置使用
	
		1.修改本地hosts文件,配置对应关系
			127.0.0.1 www.testDemoNginx.com
		2.修改nginx配置文件 conf/nginx.conf
			server { 
				listen 80; 
				server_name www.testDemoNginx.com; 
				location / { 
					root html; 
					index index.html index.htm; 
				} 
				error_page 500 502 503 504 /50x.html; 
				location = /50x.html {
					root html; 
				} 
			}
		参数说明:
			listen: 监听的端口号
			server_name: URL 地址
			location: 表示url匹配,/表示全部匹配
			root: 表示匹配成功之后进入的目录
			index: 表示默认页面
		使用:
			打开浏览器,访问www.testDemoNginx.com
		
		扩展:
			默认文件夹(html文件夹)是可以改变的,nginx默认访问的是nginx.exe同一级目录的html文件夹,我们可以修改location和root来修改这个默认访问文件夹
				location /nginx_static{
					root D:/html;
					index index.html index.htm;
				}

		根据域名,访问不同路径
			   server {
					listen       80;
					server_name  static.Tuesdayma.com;
					location / {
						root   extend/static;
						index  index.html index.htm;
					}
					error_page   500 502 503 504  /50x.html;
					location = /50x.html {
						root   html;
					}
				}
			   server {
					listen       80;
					server_name  www.Tuesdayma.com;
					location / {
						root   extend/www;
						index  index.html index.htm;
					}
					error_page   500 502 503 504  /50x.html;
					location = /50x.html {
						root   html;
					}
				}

	反向代理:
		实质:反向代理就是nginx拦截动态请求之后转发给某个Tomcat,这个在集群和分布式都可以使用这个来进行配置转发.
		
		作用:隐藏真实的访问IP地址,我们可以访问的最多的也就是公网IP,但是具体Tomcat在那个IP是不知道的,这样就能减少Tomcat被攻击,提高了服务器安全性.
		
		流程图:
			www.Tuesdayma.com/test.do
			
			客户端(匹配hosts文件) -> 域名解析 ->(公网ip)-> 公网服务器(nginx) ->内网转发-> tomcat

		配置文件修改:
			server{
				listen 80;
				server_name www.tuesdayma.com;
				location / {
					proxy_pass http://127.0.0.1:8090;
					index index.html index.htm;
				}
				error_page 500 502 503 504 /50x.html;
				location = /50x.html {
					root html;
				}
			}
		proxy_pass:127.0.0.1可以换成任何一个通的内网地址,这个IP表示你真实访问的Tomcat所在的位置,proxy_pass的值就表示你真正访问的域名是什么(站在公网服务器的角度来说)
	
	location匹配模式及顺序
		
		location = /url地址		|		=开头表示精确匹配,只有完全匹配上才能生效.
		location ^~/url地址		|		^~开头对URL路径进行前缀匹配,并且在正则之前.
		location ~正则表达式	|		~开头表示区分大小写的正则匹配.
		location ~*正则表达式	|		~*开头表示不区分大小写的正则匹配.
		location /url地址		|		不带任何修饰符，也表示前缀匹配，但是在正则匹配之后.
		location /				|		通用匹配,拦截所有,但是优先级最低,只有前面都没有被拦截的情况下,才会被拦截到这里.
		
	动静分离：
		动静分离从目前实现角度分为两种:
			一种是纯粹的把静态文件独立成单独的域名,放在独立的服务器上,也是目前主流推崇的方案;
			另外一种方法就是动态跟静态文件混合在一起发布,通过nginx来分开.
		通过location指定不同的后缀名实现不同的请求转发,通过expires参数设置,
		可以使浏览器缓存过期时间,减少与服务器之前的请求和流量.
		具体Expires定义:给一个资源设定一个过期时间,也就是说无需去服务端验证,直接通过
		浏览器自身确认是否过期即可,所以不会产生额外的流量.
		此种方法非常适合不经常变动的资源.(如果经常更新的文件,不建议使用expires来缓存),
		这里设置3d,表示在这三天之内访问这个URL,发送一个请求,比对服务器这个文件最后更新时间
		没有变化,则不会从服务器抓取,返回状态码304,如有修改,则直接从服务器重新下载,返回状态码200.
	
		静态资源： html/js/css/图片/音乐/视频等
		动态资源： 后端接口。
			注意：themleaf,freemark这些模板引擎的html不是静态资源而应该属于动态资源。
		实现动静分离的俩种方法：通过不同域名来拦截和location来拦截。
		
		不同域名来拦截：用大白话来说就是，动态请求和静态请求使用不同得到域名。比如所有静态资源都是用static.tuesdayma.com域名来访问，所有的接口资源都使用www.tuesdayma.com来请求.
		
			配置文件：
				#动态请求拦截
				server {
					listen 80;
					server_name www.Tuesdayma.com;
					location / {
						# proxy_redirect off;
						# proxy_set_header Host $host;
						# proxy_set_header X-Real-IP $remote_addr;
						# proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
						proxy_pass http://127.0.0.1:8080;
					}
					error_page 500 502 503 504 /50x.html;
					location = /50x.html {
						root html;
					}
				}
				#静态请求拦截
				server {
					listen 80;
					server_name static.Tuesdayma.com;
					location /nginx_static{
						root F:/;
						index index.html index.htm;
					}
					error_page 500 502 503 504 /50x.html;
					location = /50x.html {
						root html;
					}
				}
			优点：扩展性比较强，静态资源是什么都可以。
			缺点：存在跨域问题，所有的html全靠ajax请求来请求接口，后端域名和前端不一致导致跨域问题。
			
			解决：
				1.在nginx种把注释部分配置放开；
				2.将tomcat的所有接口配置成域名跨域访问(这个东西可以在tomcat种写个拦截器进行拦截，然后统一处理)。
				response.setHeader("Access-Control-Allow-Origin", "*");
				response.setHeader("Access-Control-Allow-Methods", "POST, GET, OPTIONS, DELETE");
				response.setHeader("Access-Control-Max-Age", "3600");
				response.addHeader("Access-Control-Allow-Headers", "Origin, X-Requested-With, Content-Type, Accept");

			
		location来拦截：这个只配置一个server,然后配置两个location,一个通过正则表达式拦截静态资源，还有一个拦截.do结尾的请求接口。
		
			优点：不存在跨域问题.
			缺点：扩展性太差，静态资源的类型不可确定，每增加一种类型都需要重新修改配置文件并且重启nginx.
	
	负载均衡
		定义：为了解决高并发问题，负载均衡服务器拦截所有的请求，采用负载均衡算法，分配到不同的tomcat上。
		
		作用: 减少单台Tomcat的压力.
		
		upstream XXX: 表示负载均衡服务器,也是通常在说的上游服务器.
		
		三种基本的负载均衡算法: 轮询/权重/IP绑定.
		
			轮询:这是nginx默认的负载均衡算法,简单来说就是从上到下按顺序轮流(127.0.0.1:8082轮完就轮到127.0.0.1:8081,127.0.0.1:8081轮完就轮到127.0.0.1:8082).注意:mzd的地方需要保持一致.
			
				配置文件:
					upstream mzd {
						server 127.0.0.1:8082;
						server 127.0.0.1:8081;
					}
					server {
						listen 80;
						server_name www.tuesdayma.com;
						location / {
							proxy_pass http://mzd;
							index index.html index.htm;
						}
						error_page 500 502 503 504 /50x.html;
						location = /50x.html {
							root html;
						}
					}
			权重:那台服务器配置好酒多轮询几次,或者想要哪几个服务器多轮询几次.简单来说就是轮到次数的比例,数字越大表示轮询的概率越大.(weight参数都设置为1的时候和轮询没什么区别)
			
				配置文件:
					upstream mzd {
						server 127.0.0.1:8082 weight=2;
						server 127.0.0.1:8081 weight=3;
					}
					server {
						listen 80;
						server_name www.tuesdayma.com;
						location / {
							proxy_pass http://mzd;
							index index.html index.htm;
						}
						error_page 500 502 503 504 /50x.html;
						location = /50x.html {
							root html;
						}
					}
					
			ip绑定: 第一次访问的时候,nginx会根据你的ip通过哈希算法,算出某个值,然后去分配哪个Tomcat,当你第二次访问,第三次访问之后...之后的任何一次访问都是去请求哪个第一次访问的Tomcat.
			
				配置文件:
					upstream mzd {
						server 127.0.0.1:8082;
						server 127.0.0.1:8081;
						ip_hash;
					}
					server {
						listen 80;
						server_name www.tuesdayma.com;
						location / {
							proxy_pass http://mzd;
							index index.html index.htm;
						}
						error_page 500 502 503 504 /50x.html;
						location = /50x.html {
							root html;
						}
					}
		问题1:可能在测试负载均衡的时候,你可能会发现浏览器一直在访问同一个Tomcat,这时候你第一反应就是我的负载均衡有问题...其实这是正常的反应,不过按上面得到方法配置应该是没有问题的,其实有俩种可能:一是确认一下所有的服务器能不能都正常访问;二是不要点浏览器上面的刷新按钮或者重新加载之类的,还有Ctrl+F5,这都可能导致这个问题.
		问题2:故障转移问题,我想应该都会有这个疑问,就是负载均衡的时候,其中一个请求被分配到哪个Tomcat挂了之后,会如何处理
		
			其实nginx有默认故障转移机制的,但是很慢,默认大约60秒左右,就会自动发送到其他的Tomcat上面去,其实就是proxy_connect_timeout的默认值
			
			解决:设置以下这些参数后,可以提高故障转移反应时间
				    server {
						listen       80;
						server_name  www.tuesdayma.com;
						location / {
							proxy_pass  http://mzd;
							proxy_connect_timeout 3s;
							proxy_read_timeout 5s;
							proxy_send_timeout 3s;
							index  index.html index.htm;
						}
						error_page   500 502 503 504  /50x.html;
						location = /50x.html {
							root   html;
						}

					}
				proxy_connect_timeout:nginx向Tomcat发起连接,即第一次握手等待Tomcat回应的超时时间,Tomcat得到这次回应只是说明能正常连接并没有相应具体请求内容.
				
				proxy_send_timeout:nginx将请求发送给Tomcat的超时时间,应该是确认能正常连接之后想Tomcat发送真正的业务请求.
				
				proxy_read_timeout:Tomcat接收到真正业务请求之后,nginx等待Tomcat响应具体请求的内容的超时时间.差不多可以理解Tomcat处理具体请求时间的最大值,也就是Tomcat必须在这个时间内做完业务逻辑处理.








linux环境下安装

	1.软件下载 http://nginx.org/
	2.安装 解压文件进入pcre目录下
		./configure 
		make && make install
	3.运行nginx
		cd /usr/local/nginx
		执行命令 ./sbin/nginx
		测试启动 ps -ef|grep nginx
		查看nginx默认端口(默认为80),使用浏览器网页形式(127.0.0.1:80)测试访问
	4.防火墙问题(windows中访问Linux中的nginx默认不能访问,需要打开防火墙)
		查看开放的端口号 firewall-cmd --list-all
		设置开放的端口号
			firewall-cmd --add-service=http –permanent 
			firewall-cmd --add-port=80/tcp --permanent 
		重启防火墙
			firewall-cmd -reload

			
nginx常用命令

	1.前提条件
		必须进入到nginx的自动生成目录的/sbin文件夹下,或者配置环境变量
	2.查看nginx的版本号
		./nginx -v
	3.启动nginx
		./nginx
		查看进程 ps -ef | grep nginx
	4.关闭nginx
		./nginx -s stop
		查看进程 ps -ef | grep nginx
	5.重新加载nginx,不需要重启服务器,自动编译
		./nginx -s reload

		
		
补充/conf/nginx.conf说明
	
	nginx.conf的组成部分
		配置文件中有很多#， 开头的表示注释内容，我们去掉所有以 # 开头的段落，精简之后的 内容如下
		worker_processes  1;

		events {
			worker_connections  1024;
		}

		http {
			include       mime.types;
			default_type  application/octet-stream;
			sendfile        on;
			keepalive_timeout  65;

			server {
				listen       80;
				server_name  localhost;

				location / {
					root   html;
					index  index.html index.htm;
				}
				error_page   500 502 503 504  /50x.html;
				location = /50x.html {
					root   html;
				}
			}
		}
		
		大致由三部分组成
		第一部分:全局块
			从配置文件到events块之间的内容,主要会设置一些影响nginx服务器整体运行的配置指令,主要包括配置运行nginx服务器的用户(组),允许生成的worker process数,进程PID存放路径,日志存放路径和类型以及配置文件的引入等.
			
			比如上面的一行:	
				worker_processes  1;
				这是nginx服务器并发处理的关键配置,worker_processes值设置的越大,可以支持的彬并发处理量也越多,但是会受到硬件,软件等设备的制约.
		
		第二部分:events块
			比如上面的配置:
				events {
					worker_connections  1024;
				}
			events块涉及的指令,主要影响nginx服务器与用户的网络连接,常用的设置包括是否开启对多
			work process下的网络连接进行序列化,是否允许同时接收多个网络连接,选取哪种事件驱动模型
			来处理连接请求,每个work process可以同时支持的最大连接数等.
			
			上述例子表示每个work process支持的最大连接数为1024.
			这部分的配置对nginx的性能影响较大,在实际中应该灵活配置.
		
		第三部分:http块(http全局块 + server块)
			http {
				include       mime.types;
				default_type  application/octet-stream;
				sendfile        on;
				keepalive_timeout  65;

				server {
					listen       80;
					server_name  localhost;

					location / {
						root   html;
						index  index.html index.htm;
					}
					error_page   500 502 503 504  /50x.html;
					location = /50x.html {
						root   html;
					}
				}
			}
		
			这算是nginx服务器配置中最频繁的部分,代理,缓存和日志定义等绝大多数功能和第三方模块的配置都在这里.
			
			http全局块:
				http全局块配置的指令包块文件引入,MIME-TYPE定义,日志自定义,连接超时时间,单链接请求数上限等.
				
			server块:
				这块和虚拟主机有密切关系,虚拟主机从用户角度来看,和一台独立的硬件主机是完全一样的,该技术的产生是为了节省互联网服务器硬件成本.
				
				每个http块可以包括多个server块,而每个server块就相当于一个虚拟主机.
				而每个server块也分为全局server块,以及可以同时包含多个location块.
				
				1.全局server块:
					最常见的配置是本虚拟机主机的监听配置和本虚拟主机的名称或ip配置.
				2.location块:
					一个server块可以配置多个location块.
					这块的主要作用是基于nginx服务器连接收到的请求字符串(例如server_name/uri-string),
					对虚拟机主机名称(也就是IP别名)之外的字符串(例如 前面的/uri-string)进行匹配,
					对特定的请求进行处理,地址定向,数据缓存和应答控制等功能,还有许多
					第三方模块配置也在这里进行.
				

		
nginx原理:
		1.master和worker
			nginx启动后,是由俩个进程组成的,master(管理者)和worker(工作者).
			一个nginx只有一个master,但是可以有多个worker
			过来的请求由master管理,worker进行争抢式的方式去获取请求.
			

	

	






















	
	
	
	



